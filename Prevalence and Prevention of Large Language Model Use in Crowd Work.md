
The paper titled "Prevalence and Prevention of Large Language Model Use in Crowd Work" investigates how frequently crowd workers utilize large language models (LLMs) like ChatGPT in text production tasks and evaluates strategies to mitigate such usage.[ACM Digital Library+3Communications of the ACM+3ACM Digital Library+3](https://cacm.acm.org/research/prevalence-and-prevention-of-large-language-model-use-in-crowd-work/?utm_source=chatgpt.com)

**Key Findings:**

- **Widespread LLM Usage:** Approximately 33â€“35% of summaries produced by crowd workers on the Prolific platform were likely generated using LLMs, even without explicit instructions to do so.[Communications of the ACM](https://cacm.acm.org/research/prevalence-and-prevention-of-large-language-model-use-in-crowd-work/?utm_source=chatgpt.com)
    
- **Quality vs. Diversity:** While LLM-assisted summaries were generally of high quality, they exhibited greater homogeneity compared to human-generated content, potentially compromising the diversity of responses in research studies.[Communications of the ACM](https://cacm.acm.org/research/prevalence-and-prevention-of-large-language-model-use-in-crowd-work/?utm_source=chatgpt.com)
    
- **Mitigation Strategies:** Implementing measures such as disabling copy-paste functionality or directly requesting workers not to use LLMs reduced LLM usage by nearly 50%. However, these interventions did not entirely eliminate LLM reliance.[Communications of the ACM+1ACM Digital Library+1](https://cacm.acm.org/research/prevalence-and-prevention-of-large-language-model-use-in-crowd-work/?utm_source=chatgpt.com)
    
- **Demographic Correlations:** Younger workers and those who frequently use LLMs in daily life were more inclined to employ them in crowd work tasks.[ACM Digital Library+3Communications of the ACM+3ACM Digital Library+3](https://cacm.acm.org/research/prevalence-and-prevention-of-large-language-model-use-in-crowd-work/?utm_source=chatgpt.com)
    
- **Impact on Research Integrity:** The use of LLMs by crowd workers poses challenges for studies aiming to capture genuine human behavior, preferences, or opinions, as LLM-generated data may not accurately reflect the intended human diversity.[Communications of the ACM](https://cacm.acm.org/research/prevalence-and-prevention-of-large-language-model-use-in-crowd-work/?utm_source=chatgpt.com)
    

**Recommendations:**

- **Assess Research Objectives:** Researchers should evaluate whether their studies require authentic human responses and consider the potential impact of LLM usage on data integrity.[Communications of the ACM+1ACM Digital Library+1](https://cacm.acm.org/research/prevalence-and-prevention-of-large-language-model-use-in-crowd-work/?utm_source=chatgpt.com)
    
- **Implement Preventative Measures:** To preserve data quality, researchers can employ strategies to deter LLM usage, such as modifying task interfaces to hinder easy LLM integration or explicitly instructing workers to avoid LLM assistance.[Communications of the ACM+1ACM Digital Library+1](https://cacm.acm.org/research/prevalence-and-prevention-of-large-language-model-use-in-crowd-work/?utm_source=chatgpt.com)
    
- **Continuous Monitoring:** Given the rapid evolution of LLM capabilities and integration into daily workflows, ongoing assessment and adaptation of mitigation strategies are essential to maintain the validity of crowd-sourced data.[Communications of the ACM](https://cacm.acm.org/research/prevalence-and-prevention-of-large-language-model-use-in-crowd-work/?utm_source=chatgpt.com).




